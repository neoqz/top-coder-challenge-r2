Create / update **AGENT.md** â€“ final tuning guide
=================================================

> **Public cases are for iteration only.**  \
> Your answers on **private cases** (no outputs provided) determine the final
> score. **Bottom line:** do **NOT** over-fit the public setâ€”it will hurt your
> private score!

---

## ðŸŽ¯ Success Criteria

| Metric                | Target                          |
|-----------------------|---------------------------------|
| **Public Score**      | **< 8 000**                     |
| **Validation ScoreÂ¹** | â‰¤ 1.05 Ã— Public Score           |
| **Runtime per call**  | < 0 .10 s on (14 d, 1317 mi, $2503) |

Â¹Validation = fixed 10 % slice of the public data (seed 0).  
Guard + slice prevent over-fit.

---

## ðŸ”„ Agent Loop (anti-over-fit)

1. **Load** public data once â†’ NumPy arrays.  
2. **predict(constants)** â€“ multi-component rule (per-diem, tiered mileage, spend curve, efficiency bonus, receipt bump).  
3. **score(constants, mask=None)** â†’ `(score, avg_err, exact)` where  
   `score = sum(abs_err) + mean(abs_err)`.  
4. **Validation + Fold Guard**  
   * Fixed 10 % validation mask (seed 0).  
   * 5 random 80 : 20 folds; accept candidate only if it wins â‰¥ 4 folds.  
5. **Simulated Annealing**  
   * 10 restarts Ã— 30 000 iterations  
   * Temperature `T = 15000 Ã— 0.97**iter`  
   * Perturb 3 random constants Â± 15 % (rounded 4 dp).  
6. **Early-stop** when `train < 8 000` **and** `val â‰¤ 1.05 Ã— train`.  
7. **On success**  
   * Overwrite `calculate.py` with tuned constants (stdlib only, deterministic).  
   * `./generate_results.sh` â†’ `private_results.txt`.  
   * Update README badge: `**Score:** <train_score> (public, exact <n>/1000)`.  
   * `git add calculate.py README.md private_results.txt`  
   * `git commit -m "tune: constants achieve score <train_score>"`  
   * `git push`  
   * Print:  
     ```
     Final Score: <train>  Val: <val>  Runtime: <sec>s
     ```
8. **On failure** (`best â‰¥ 8 000` after all iters)  
   * Leave repo unchanged.  
   * Print `Need more tuning â€“ best so far <score>` and exit with code 1.

---

## ðŸ§ª Evaluation Scripts

*Run these locally to track progress.*

```bash
./eval.sh                # runs on 1 000 public cases

./generate_results.sh    # creates private_results.txt for submission

Anti-Over-fit Checklist
 Validation â‰¤ 1.05 Ã— Public Score

 Candidate wins â‰¥ 4 of 5 folds

 Components rounded to cents before summing

 Constants rounded to 4 dp

 Monotonic sanity: more miles never pays less
```
